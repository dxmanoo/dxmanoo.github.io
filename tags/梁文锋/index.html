<!doctype html><html lang=zh-cn dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>梁文锋 | PinSomeWords</title>
<meta name=keywords content><meta name=description content><meta name=author content><link rel=canonical href=https://dxmanoo.github.io/tags/%E6%A2%81%E6%96%87%E9%94%8B/><link crossorigin=anonymous href=/assets/css/stylesheet.83e4af8b142355dea6e03e534b64a817783cc07cc6f402c58aa607184286a8d5.css integrity="sha256-g+SvixQjVd6m4D5TS2SoF3g8wHzG9ALFiqYHGEKGqNU=" rel="preload stylesheet" as=style><link rel=icon href=https://dxmanoo.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://dxmanoo.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://dxmanoo.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://dxmanoo.github.io/apple-touch-icon.png><link rel=mask-icon href=https://dxmanoo.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://dxmanoo.github.io/tags/%E6%A2%81%E6%96%87%E9%94%8B/index.xml><link rel=alternate hreflang=zh-cn href=https://dxmanoo.github.io/tags/%E6%A2%81%E6%96%87%E9%94%8B/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://dxmanoo.github.io/tags/%E6%A2%81%E6%96%87%E9%94%8B/"><meta property="og:site_name" content="PinSomeWords"><meta property="og:title" content="梁文锋"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="梁文锋"><meta name=twitter:description content></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dxmanoo.github.io/ accesskey=h title="PinSomeWords (Alt + H)">PinSomeWords</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://dxmanoo.github.io/posts/ title=文章><span>文章</span></a></li><li><a href=https://dxmanoo.github.io/archives/ title=归档><span>归档</span></a></li><li><a href=https://dxmanoo.github.io/tags/ title=标签><span>标签</span></a></li><li><a href=https://dxmanoo.github.io/about/ title=关于><span>关于</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://dxmanoo.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://dxmanoo.github.io/tags/>Tags</a></div><h1>梁文锋
<a href=/tags/%E6%A2%81%E6%96%87%E9%94%8B/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>一名程序员眼里中国量化投资的未来</h2></header><div class=entry-content><p>一名程序员眼里中国量化投资的未来 时间：2019年8月30日
2019年8月30日，34岁梁文锋在金牛奖颁奖仪式上，发表主题演讲《一名程序员眼里中国量化投资的未来》。
首先，预测中国量化投资未来，一个方法是看美国现状。美国资产管理有两个趋势：一个是共同基金逐渐指数化，另一个趋势是对冲基金逐渐走向量化。国外对冲基金，类似中国证券私募。最初的对冲基金都不是量化，这个表是2004年全球对冲基金资管规模前10名，大部分都不是量化。2018年排名，量化已经占了前面多数，我们熟悉的桥水排第1，AQR排第2，文艺复兴排第4。最近十几年，量化基金在美国逐渐变成对冲基金的主流，甚至很多人以为对冲基金是量化基金。我们是对冲基金，我今天主要讲对冲基金里的量化基金。
美国经验看，量化私募的管理规模可以做得很大。全球最大的对冲基金，桥水管理规模是一万亿人民币左右，国内大的量化公司在100～200亿之间，我们可能还有几十倍增长空间。中国真的有私募能做1万亿吗？应该是可以的。以后中国经济体量与美国差不多，国内最大团队应该能管23千亿。如果股市扩容，衍生品市场发展，能管45千亿。再加上海外市场，就有1万亿。
国外多量化公司，他们都在做什么，都在做高频？不是，高频容纳的钱很少，不是资产管理主流。答案是所有策略都做，从宏观对冲，到股票基本面，到股票量价，到大宗商品，到债券，主战场是股票与债券。全球最大的对冲基金桥水，是做宏观量化。全球第二大对冲基金AQR，是做股票基本面。越是低频的策略，容量越大。所有原来人类做的策略，现在量化都在做。国内对冲基金，现在大家主要都是做量价策略，我们整体上比美国落后。美国经验看，策略类型上面，我们应该还有很大发展空间。
量化与非量化，到底怎么区分。根据中国国情，对量化投资做个定义。有人说量化投资是程序化下单，这不对。不少量化公司是手工下单，传统公募很多是程序化下单，有成熟的VWAP系统。有人说是用数量化方法进行研究，也不对。现代的投资研究，很多都是要用数量化方法，这个定义没有区分度，所有人都可以说自己是量化的。有人说主观投资需要深入个股，量化不用看个股，也不对，至少我们个股看得挺细，我们美国同行看个股也是非常细。
真正区别是什么，答案是，投资决策过程中，是用数量化方法进行决策，还是用人进行决策。区别不是交易，不是研究手段，是决策方式。
量化公司有很多交易员与研究员，会发现量化公司没有基金经理，基金经理是一堆服务器。人做投资决策时，它是种艺术，要凭感觉。程序决策时，它是科学，有最优解。
量化投资，以后还需要人吗，当然需要，需要大量程序员与研究员。
我们看下国内量化投资，大家都在做什么。当前投到中国市场的量化资金，我们估算大概在2,500亿~5,000亿。超过一半投到股票策略，其次是商品CTA，剩下的很少。历史收益看，股票收益也是比商品CTA要好一点，我们今天集中讨论股票策略。这个表是我们与同行一起估算出来，不一定精确，大轮廓差不多。如果你要投量化，按这个表找投顾就对了。
股票策略，传统上分成4种。最重要的是第一种，日间量价模型。大家经常听说的多因子、alpha都是说日间量价模型，规模大概有两千亿。第二重要的，是日内回转模型，俗称股票T0，有大几百亿。最后还有两种，基本面模型与事件驱动模型，目前不是重点。这是私募数据，公募还有1,200亿左右在做基本面量化。我们今天只讨论私募，这四种模型都有效。
传统上，所有的模型都是多因子模型，通过选股与择时来获取超额收益。2017年以前，多因子模型是万能的，以前我们都希望模仿worldquant的模式，是找很多的人来挖因子。同行里，大家竞争的是谁的因子更加有效。现在你要再挖出一些很有效的因子，已经很难。2017年之后，行业发生变化，传统的多因子框架逐渐被AI取代。2019年之后，又逐渐被更新的集成框架取代。
作为私募，投资人对我们期望是很高的，如果1年跑赢指数低于25%，投资人是不满意的，私募之间竞争很激烈。我们每个星期，都会拿到同行业绩数据，这个星期谁跑赢多少，大家放到一起比，如果落后了，客户就马上会打电话来。我们压力很大的，我相信同行的所有人压力都大。正是这样的压力，逼得我们不断提升投资能力，加班改策略，一偷懒就落后。我们向客户收费也高，远高于公募，这个业绩与压力也是公平的。
我们经常被问：量化投资，到底是赚了谁的钱？答案很简单，量化赚了原来人类投资者赚的钱。人类投资者分两个流派，一种叫技术面，一种叫基本面。说得更具体一点，现在量化赚的是技术面流派原来赚的钱。谁来告诉我，技术面流派赚了谁的钱？技术面流派，现在赚钱，已经比以前难很多，程序有2~3千亿的钱，每天在做同样的事，使得市场有效性大幅度提高。再过几年，人类会更难，程序一直在进步。现在是2019年，在技术面上，程序已经远远超越一般人类高手。
**量化私募整个行业的进步，大致符合摩尔定律，每18个月投资能力翻一倍。**这几年来，量化投资平均收益率，差不多没变化，市场有效性在不断提高。**这是符合逻辑的，投资能力提高一倍，市场有效性还一样，赚的钱应该是原来2倍才对。**市场的有效性提高了，一个证据是人类高手很难赚钱，另一个证据是2年前有效的量化策略，现在慢慢失效。**量化的投资能力，还有很大提升空间。**我们预计未来几年，中国股票市场，有效性会进一步提高。这是历史趋势，不可阻挡。
我们经常被问到一个问题：以后市场非常有效，是不是大家都不赚钱。美国情况看，市场不会100%有效，市场100%有效，对冲基金就消失了，谁来维持流动性与价格？市场会在接近完全有效时，达成均衡，使得对冲基金刚好能cover公司运营成本、客户资金与风险成本。全球看，对冲基金都不是暴利行业，跟一级市场与房地产来比的话。我们所处的历史阶段大概在这里，我们离市场完全有效应该还很远，至少未来几年，我们不需要考虑这个问题。
最后，我们做两个预测。一个短预测，一个长预测。如果这两个预测成立，量化投资收益率，还能持续若干年。
短预测：未来1~2年 未来1~2年，行业的提升，应该来自多策略结合。多策略结合，不是简单的分散投资。分散投资是这样的，4亿资金，1亿做A模型，1亿做B模型，1亿做C模型，1亿做D模型。这样做的缺点是，收益率是4个模型的平均。
我们说的多策略结合，是叠加，4亿既做A模型，同样4亿资金，也做B模型、C模型、D模型，最后合成大的、包罗万象的策略，不属于传统策略类别里哪一种。2018年，日间alpha叠加日内T0效果很好，它已经落后，现在需要更多策略，用更领先方法来叠加。这个听起来很有道理，做起来很难，难点不是在策略或者技术本身，而是在私募公司自己商业逻辑上。每个模型都需要一个团队，原来一个团队能管几十个亿，现在要很多个团队加起来，才能管几十个亿，成本多了很多倍，公司收入没有同比例增加。
据我们观察，这个趋势已经在发生，你不做，别人会来做，最近业绩最好的几家私募，都是多策略。我们预计这个过程会加速，随着市场有效性提高，收益率下降，要靠单策略取得好的收益，已经很难。以后策略整体会非常复杂，工作量大，门槛高，没有能力组织多个团队的量化公司，会比较难活下去。量化投资会向头部公司集中，使得头部公司，有足够资源做这些更复杂的策略。我们觉得在多策略结合上，空间还是很大，按照我们自己进度看，未来12年还做不完。如果这个预测成立，量化私募未来12年还能有比较好收益。
长预测：未来3~5年 总有一天，技术面的波动会越来越小，技术进步到达瓶颈。未来量化投资，一定会瓜分这部分人原来赚的钱，原来基本面流派人赚的钱。基本面上，市场有效性目前还是比较差，这里有很多空间。量化做基本面，技术上完全可行。有人说基本面，每家公司不一样，没法量化，这是不对的。首先，美国可以量化，为什么中国不行。其次，技术面可以量化，为什么基本面不行。大概2015年前后，基本面量化，在私募里曾经流行过一段时间，那时市场有效性没现在这么高，用传统多因子框架就能赚钱。2017年开始，收益率逐步降低，做基本面量化的私募团队，失去竞争力，已经逐步被淘汰，公募还在做，私募需要把基本面量化提升到更高的水平。
完成这个使命的，不会是老的那批人，而是新的能力更强的人，用更复杂、更精细的方法，才能把这个事做出来。我们现在产品里，已经叠加基本面量化的模型，效果很好，还只是用了传统方法。要更进一步，需要精细化做，成本比技术面高很多。要做到AQR这样水平，我们保守估计，团队成本，在每年10亿人民币以上，只能一步一步来。以后量化私募能管1,000亿，这个成本是可以接受的，商业模式上没有问题。基本面量化，还有很长路要走，它要达到现在技术面量化的高度，应该还差几个摩尔定律周期。这一天，肯定是在我们有生之年会看到。
最后问题是，如果对冲基金赚了技术面的钱，又赚了基本面的钱，普通人怎么办，我们回到美国身上找到答案。
对冲基金只赚了波动、流动性、定价的钱，没有赚走beta的钱。美国最大的对冲基金桥水，资管规模1万亿人民币；美国最大的共同基金贝莱德，资管规模是45万亿；在共同基金面前，对冲基金是小不点。
市场有效的时候，直接买指数就可以，指数是真正的价值投资，财富主体还是在老百姓手上。
作为对冲基金，我们的使命是，提高中国二级市场的有效性。</p></div><footer class=entry-footer><span title='2025-02-23 00:52:21 +0800 +0800'>February 23, 2025</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to 一名程序员眼里中国量化投资的未来" href=https://dxmanoo.github.io/posts/202502230003/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>疯狂的幻方：一家隐形AI巨头的大模型之路 - 36氪</h2></header><div class=entry-content><p>疯狂的幻方：一家隐形AI巨头的大模型之路 - 36氪 文 | 于丽丽
编辑 | 刘旌
在蜂拥而至的大模型团战中，幻方大概是最异类的一个。
这是一场注定是少数人的游戏，很多创业公司在大厂入局后开始调整方向甚至萌生退意，而这家量化基金却孤绝前行。
5月，幻方把下场做大模型的独立新组织，命名为「深度求索」，并强调将专注于做真正人类级别的人工智能。他们的目标，不只是复刻ChatGPT，还要去研究和揭秘通用人工智能（AGI）的更多未知之谜。
不仅如此，在这个被认为格外依赖稀缺人才的赛道，幻方还试图去集结一批有执念的人，并祭出了他们认为的最大武器：一群人的好奇心。
在量化领域，幻方是一家抵达过千亿规模的「顶级基金」，但它被这波AI新浪潮集中关注到，其实还颇具戏剧性。
当国内云厂商高性能GPU芯片缺货成为限制中国生成式AI诞生的最直接因素时，据《财经十一人》报道，国内拥有超过1万枚GPU的企业不超过5家。而除几家头部大厂外，还包括一家名为幻方的量化基金公司。 通常认为，1万枚英伟达A100芯片是做自训大模型的算力门槛。
其实，这家很少被置于人工智能视野打量的公司，早已是一家隐秘的AI巨头：2019年，幻方量化成立AI公司，其自研的深度学习训练平台「萤火一号」总投资近2亿元，搭载了1100块GPU；两年后，「萤火二号」的投入增加到10亿元，搭载了约1万张英伟达A100显卡。
这意味着，单从算力看，幻方甚至比很多大厂都更早拿到了做ChatGPT的入场券。
只是大模型对算力、算法和数据都有强依赖，所以起步就需要5000万美金，训练一次需要上千万美金，非百亿美金公司其实很难持续跟进。各种艰难之下，幻方却很乐观，创始人梁文锋告诉我们：「关键是我们想做这件事，能做这件事，那我们就是最合适的人选之一。」
这种谜之乐观，首先来自幻方的独特成长路径。
量化投资是一个源自美国的舶来品，这使得几乎所有中国的头部量化基金创始班底，都或多或少有过美国或欧洲对冲基金的履历。唯独幻方是一个例外：它完全是本土班底起家，独自摸索着长大。
2021年，成立仅六年的幻方，抵达千亿规模，并被称为「量化四大天王」之一。
以局外人杀入的成长路径，让幻方始终像一个搅局者。多位行业人士向我们表示，幻方「无论研发体系、产品还是销售，都始终在用一种崭新的方式，切入到这个行业中来。」
一家头部量化基金创始人认为，这些年的幻方，始终「没有按照某种约定成俗的道路在走」，而是「按照他们想要的方式」，即便是有点离经叛道或者争议，「也敢大大方方说出来，然后按照自己的想法去做」。
关于幻方的成长奥秘，幻方内部将之归结为「选用了一批没有经验但有潜能的人，以及有一个可以让创新发生的组织架构和企业文化」，他们认为这也将是大模型创业公司可以与大厂竞争的秘密所在。
而更关键的秘密，或许来自幻方的创始人梁文锋。
还在浙江大学攻读人工智能时，梁文锋就无比笃信「人工智能一定会改变世界」，而2008年，这还是一个不被认同的执念。
毕业后，他没有像周围人一样去大厂做个程序员，而是躲在成都的廉价出租屋里，不停接受进入诸多场景中尝试的挫败，最终切入了最复杂场景之一的金融，并成立了幻方。
一个有趣的细节是，在最早几年，曾有个同样疯癫的、在深圳城中村做着「不靠谱」飞行器的朋友拉他入伙。后来这个朋友做成了一个千亿美金的公司，名叫：大疆。
也因此，在做大模型必然涉及的钱、人、算力等话题外，我们还和幻方创始人梁文锋特别聊了聊，怎样的组织架构可以让创新发生，以及人的疯狂可以持续多久。
创业十余年，这是这位鲜少露面的「技术宅」型创始人第一次公开受访。
巧合的是，4月11日，幻方在发布做大模型公告时，也引用了法国新浪潮导演特吕弗曾告诫青年导演的一句话：「务必要疯狂地怀抱雄心，且还要疯狂地真诚。」
1. 做研究，做探索 「做最重要、最困难的事」 36氪：前不久，幻方发公告决定下场做大模型，一家量化基金为什么要做这样一件事？
梁文锋： 我们做大模型，其实跟量化和金融都没有直接关系。我们独建了一个名为深度求索的新公司来做这件事。
幻方的主要班底里，很多人是做人工智能的。当时我们尝试了很多场景，最终切入了足够复杂的金融，而通用人工智能可能是下一个最难的事之一，所以对我们来说，这是一个怎么做的问题，而不是为什么做的问题。
36氪：你们要自训一个大模型，还是某个垂直行业——比如金融相关的大模型？
梁文锋： 我们要做的是通用人工智能，也就是AGI。语言大模型可能是通往AGI的必经之路，并且初步具备了AGI的特征，所以我们会从这里开始，后边也会有视觉等。
36氪：因为大厂的入局，很多创业型公司都放弃了只做通用型大模型的大方向。
梁文锋： 我们不会过早设计基于模型的一些应用，会专注在大模型上。
36氪：很多人认为，创业公司在大厂形成共识后下场，已经不是一个好的时间点。
梁文锋： 现在看起来，无论大厂，还是创业公司，都很难在短时间内建立起碾压对手的技术优势。因为有OpenAI指路，又都基于公开论文和代码，最晚明年，大厂和创业公司都会把自己的大语言模型做出来。
大厂和创业公司都各有机会。现有垂类场景不掌握在初创公司手上，这个阶段对初创公司不太友好。但因为这种场景说到底也是分散的、碎片化的小需求，所以它又是更适合灵活的创业型组织的。从长期看，大模型应用门槛会越来越低，初创公司在未来20年任何时候下场，也都有机会。
我们的目标也很明确，就是不做垂类和应用，而是做研究，做探索。
36氪：为什么你的定义是「做研究、做探索」？
梁文锋： 一种好奇心驱动。从远处说，我们想去验证一些猜想。比如我们理解人类智能本质可能就是语言，人的思维可能就是一个语言的过程。你以为你在思考，其实可能是你在脑子里编织语言。这意味着，在语言大模型上可能诞生出类人的人工智能（AGI）。
从近处说，GPT4还有很多待解之谜。我们去复刻的同时，也会做研究揭秘。
36氪：但研究意味着要付出更大的成本。
梁文锋： 只做复刻的话，可以在公开论文或开源代码基础上，只需训练很少次数，甚至只需finetune（微调）一下，成本很低。而做研究，要做各种实验和对比，需要更多算力，对人员要求也更高，所以成本更高。
36氪：那研究经费哪里来？
梁文锋： 幻方作为我们的出资人之一，有充足的研发预算，另外每年有几个亿的捐款预算，之前都是给公益机构，如果需要，也可以做些调整。
36氪：但做基础层大模型，没有两三亿美元，连牌桌都上不了，我们如何支撑它的持续投入？
梁文锋： 我们也在找不同出资方在谈。接触下来，感觉很多VC对做研究有顾虑，他们有退出需求，希望尽快做出产品商业化，而按照我们优先做研究的思路，很难从VC那里获得融资。但我们有算力和一个工程师团队，相当于有了一半筹码。
36氪：我们对商业模式做了哪些推演和设想？
梁文锋： 我们现在想的是，后边可以把我们的训练结果大部分公开共享，这样可以跟商业化有所结合。我们希望更多人，哪怕一个小app都可以低成本去用上大模型，而不是技术只掌握在一部分人和公司手中，形成垄断。
36氪：一些大厂后期也会有一些服务提供，你们差异化的部分是什么？
梁文锋： 大厂的模型，可能会和他们的平台或生态捆绑，而我们是完全自由的。
36氪：无论如何，一个商业公司去做一种无限投入的研究性探索，都有些疯狂。
...</p></div><footer class=entry-footer><span title='2025-02-23 00:29:35 +0800 +0800'>February 23, 2025</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to  疯狂的幻方：一家隐形AI巨头的大模型之路 - 36氪" href=https://dxmanoo.github.io/posts/202502230002/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>揭秘DeepSeek：一个更极致的中国技术理想主义故事 ｜36氪独家</h2></header><div class=entry-content><p>揭秘DeepSeek：一个更极致的中国技术理想主义故事 ｜36氪独家 文 | 于丽丽
编辑 | 刘旌
中国的7家大模型创业公司中，DeepSeek（深度求索）最不声不响，但它又总能以出其不意的方式被人记住。
一年前，这种出其不意源自它背后的量化私募巨头幻方，是大厂外唯一一家储备万张A100芯片的公司，一年后，则来自它才是引发中国大模型价格战的源头。
在被AI连续轰炸的5月，DeepSeek一跃成名。起因是他们发布的一款名为DeepSeek V2的开源模型，提供了一种史无前例的性价比：推理成本被降到每百万token仅1块钱，约等于Llama3 70B的七分之一，GPT-4 Turbo的七十分之一。
DeepSeek被迅速冠以“AI界拼多多”之称的同时，字节、腾讯、百度、阿里等大厂也按耐不住，纷纷降价。中国大模型价格战由此一触即发。
弥漫的硝烟其实掩盖了一个事实：与很多大厂烧钱补贴不同，DeepSeek是有利润的。
这背后，是DeepSeek对模型架构进行了全方位创新。它提出的一种崭新的MLA（一种新的多头潜在注意力机制）架构，把显存占用降到了过去最常用的MHA架构的5%-13%，同时，它独创的DeepSeekMoESparse结构，也把计算量降到极致，所有这些最终促成了成本的下降。
在硅谷，DeepSeek被称作“来自东方的神秘力量”。SemiAnalysis首席分析师认为，DeepSeek V2论文“可能是今年最好的一篇”。OpenAI前员工Andrew Carr认为论文“充满惊人智慧”，并将其训练设置应用于自己的模型。而OpenAI前政策主管、Anthropic联合创始人Jack Clark认为，DeepSeek“雇佣了一批高深莫测的奇才”，还认为中国制造的大模型，“将和无人机、电动汽车一样，成为不容忽视的力量。”
在基本由硅谷牵动故事进展的AI浪潮里，这是罕有的情形。 多位行业人士告诉我们，这种强烈的反响源自架构层面的创新，是国产大模型公司乃至全球开源基座大模型都很罕见的尝试。 一位AI研究者表示，Attention架构提出多年来，几乎未被成功改过，更遑论大规模验证。“这甚至是一个做决策时就会被掐断的念头，因为大部分人都缺乏信心。”
而另一方面，国产大模型之前很少涉足架构层面的创新，也是因为很少有人主动去击破那样一种成见：美国更擅长从0-1的技术创新，而中国更擅长从1-10的应用创新。 何况这种行为非常不划算——新一代模型，过几个月自然有人做出来，中国公司只要跟随、做好应用即可。对模型结构进行创新，意味着没有路径可依，要经历很多失败，时间、经济成本都耗费巨大。
DeepSeek显然是逆行者。在一片认为大模型技术必然趋同，follow是更聪明捷径的喧哗声中，DeepSeek看重“弯路”中积累的价值，并认为中国的大模型创业者除应用创新外，也可以加入到全球技术创新的洪流中。
DeepSeek的很多抉择都与众不同。截至目前，7家中国大模型创业公司中，它是唯一一家放弃“既要又要”路线，至今专注在研究和技术，未做toC应用的公司，也是唯一一家未全面考虑商业化，坚定选择开源路线甚至都没融过资的公司。这些使得它经常被遗忘在牌桌之外，但在另一端，它又经常在社区被用户“自来水”式传播。
DeepSeek究竟是如何炼成的？我们为此访谈了甚少露面的DeepSeek创始人梁文锋。
这位从幻方时代，就在幕后潜心研究技术的80后创始人，在DeepSeek时代，依旧延续着他的低调作风，和所有研究员一样，每天“看论文，写代码，参与小组讨论”。
和很多量化基金创始人都有过海外对冲基金履历，多出身物理、数学等专业不同的是，梁文锋一直是本土背景，早年就读的也是浙江大学电子工程系人工智能方向。
多位行业人士和DeepSeek研究员告诉我们，梁文锋是当下中国AI界非常罕见的“兼具强大的infra工程能力和模型研究能力，又能调动资源”、“既可以从高处做精准判断，又可以在细节上强过一线研究员”的人，他拥有“令人恐怖的学习能力”，同时又“完全不像一个老板，而更像一个极客”。
这是一次尤为难得的访谈。访谈里，这位技术理想主义者，提供了目前中国科技界特别稀缺的一种声音：他是少有的把“是非观”置于“利害观”之前，并提醒我们看到时代惯性，把“原创式创新”提上日程的人。
一年前，DeepSeek刚下场时，我们初次访谈了梁文锋：《疯狂的幻方：一家隐形AI巨头的大模型之路》。如果说当时那句**「务必要疯狂地怀抱雄心，且还要疯狂地真诚」**还是一句美丽的口号，一年过去，它已经在成为一种行动。
以下为对话部分：
价格战第一枪是怎么打响的？ 「暗涌」：DeepSeek V2模型发布后，迅速引发一场血雨腥风的大模型价格战，有人说你们是行业的一条鲶鱼。
梁文锋：我们不是有意成为一条鲶鱼，只是不小心成了一条鲶鱼。
「暗涌」：这个结果让你们意外吗？
梁文锋：非常意外。没想到价格让大家这么敏感。我们只是按照自己的步调来做事，然后核算成本定价。我们的原则是不贴钱，也不赚取暴利。这个价格也是在成本之上稍微有点利润。
「暗涌」：5天后智谱AI就跟进了，之后是字节、阿里、百度、腾讯等大厂。
梁文锋：智谱AI降的是一个入门级产品，和我们同级别的模型仍然收费很贵。字节是真正第一个跟进的。旗舰模型降到和我们一样的价格，然后触发了其它大厂纷纷降价。因为大厂的模型成本比我们高很多，所以我们没想到会有人亏钱做这件事，最后就变成了互联网时代的烧钱补贴的逻辑。
「暗涌」：外部看来，降价很像在抢用户，互联网时代的价格战通常如此。
梁文锋：抢用户并不是我们的主要目的。我们降价一方面是因为我们在探索下一代模型的结构中，成本先降下来了，另一方面也觉得无论API，还是AI，都应该是普惠的、人人可以用得起的东西。
「暗涌」：在这之前，大部分中国公司都会直接copy这一代的Llama结构去做应用，为什么你们会从模型结构切入？
梁文锋：如果目标是做应用，那沿用Llama结构，短平快上产品也是合理选择。但我们目的地是AGI，这意味着我们需要研究新的模型结构，在有限资源下，实现更强的模型能力。这是scale up到更大模型所需要做的基础研究之一。除了模型结构，我们还做了大量其他的研究，包括怎么构造数据，如何让模型更像人类等，这都体现在我们发布的模型里。另外，Llama的结构，在训练效率和推理成本上，和国外先进水平估计也已有两代差距。
「暗涌」：这种代差主要来自哪里？
梁文锋：首先训练效率有差距。我们估计，国内最好的水平和国外最好的相比，模型结构和训练动力学上可能有一倍的差距，光这一点我们要消耗两倍的算力才能达到同样效果。另外数据效率上可能也有一倍差距，也就是我们要消耗两倍的训练数据和算力，才能达到同样的效果。合起来就要多消耗4倍算力。我们要做的，正是不停地去缩小这些差距。
「暗涌」：大部分中国公司都选择既要模型又要应用，为什么DeepSeek目前选择只做研究探索？
梁文锋：因为我们觉得现在最重要的是参与到全球创新的浪潮里去。过去很多年，中国公司习惯了别人做技术创新，我们拿过来做应用变现，但这并非是一种理所当然。这一波浪潮里，我们的出发点，就不是趁机赚一笔，而是走到技术的前沿，去推动整个生态发展。
「暗涌」：互联网和移动互联网时代留给大部分人的惯性认知是，美国擅长搞技术创新，中国更擅长做应用。
梁文锋：我们认为随着经济发展，中国也要逐步成为贡献者，而不是一直搭便车。 过去三十多年IT浪潮里，我们基本没有参与到真正的技术创新里。我们已经习惯摩尔定律从天而降，躺在家里18个月就会出来更好的硬件和软件。Scaling Law也在被如此对待。
但其实，这是西方主导的技术社区一代代孜孜不倦创造出来的，只因为之前我们没有参与这个过程，以至于忽视了它的存在。
真正的差距不是一年或两年，而是原创和模仿之差 「暗涌」：为什么DeepSeek V2会让硅谷的很多人惊讶？
梁文锋：在美国每天发生的大量创新里，这是非常普通的一个。他们之所以惊讶，是因为这是一个中国公司，以创新贡献者的身份，加入到他们游戏里去。 毕竟大部分中国公司习惯follow，而不是创新。
「暗涌」：但这种选择放在中国语境里，也过于奢侈。大模型是一个重投入游戏，不是所有公司都有资本只去研究创新，而不是先考虑商业化。
梁文锋：创新的成本肯定不低，过去那种拿来主义的惯性也和过去的国情有关。但现在，你看无论中国的经济体量，还是字节、腾讯这些大厂的利润，放在全球都不低。我们创新缺的肯定不是资本，而是缺乏信心以及不知道怎么组织高密度的人才实现有效的创新。
「暗涌」：为什么中国公司——包括不缺钱的大厂，这么容易把快速商业化当第一要义？
梁文锋：过去三十年，我们都只强调赚钱，对创新是忽视的。创新不完全是商业驱动的，还需要好奇心和创造欲。我们只是被过去那种惯性束缚了，但它也是阶段性的。
「暗涌」：但你们究竟是一个商业组织，而非一个公益科研机构，选择创新，又通过开源分享出去，那要在哪里形成护城河？像5月这次MLA架构的创新，也会很快被其他家copy吧？
梁文锋：在颠覆性的技术面前，闭源形成的护城河是短暂的。即使OpenAI闭源，也无法阻止被别人赶超。 所以我们把价值沉淀在团队上，我们的同事在这个过程中得到成长，积累很多know-how,形成可以创新的组织和文化，就是我们的护城河。
开源，发论文，其实并没有失去什么。对于技术人员来说，被follow是很有成就感的事。其实，开源更像一个文化行为，而非商业行为。给予其实是一种额外的荣誉。一个公司这么做也会有文化的吸引力。
...</p></div><footer class=entry-footer><span title='2025-02-23 00:17:39 +0800 +0800'>February 23, 2025</span>&nbsp;·&nbsp;1 min</footer><a class=entry-link aria-label="post link to 揭秘DeepSeek：一个更极致的中国技术理想主义故事 ｜36氪独家" href=https://dxmanoo.github.io/posts/202502230001/></a></article></main><footer class=footer><span>&copy; 2025 <a href=https://dxmanoo.github.io/>PinSomeWords</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>